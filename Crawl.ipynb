{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "html = requests.get('https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day&sectionId=101&date=20200204').text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "title_list = soup.select('.ranking_headline')\n",
    "start_date = '20190204'\n",
    "end_date = '20200204'\n",
    "datetime = pd.date_range(start_date, end_date) \n",
    "datetime= datetime.strftime(\"%Y%m%d\").tolist()\n",
    "\n",
    "datetime\n",
    "economic = []\n",
    "\n",
    "# print(title_list[1].get_text().strip())\n",
    "for i in datetime:\n",
    "    url = 'https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day&sectionId=101&date='+i\n",
    "    request = urllib.request.Request(url)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    soup_class = soup.select('.ranking_headline')\n",
    "    for index in soup_class:\n",
    "        title = index.get_text().strip()\n",
    "        economic.append([title])\n",
    "\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#여기에 함수를 구현해봅시다.\n",
    "url = \"https://www.naver.com/\"\n",
    "req = urllib.request.urlopen(url)\n",
    "res = req.read()\n",
    "\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "keywords = soup.find_all('div',class_='area_link')\n",
    "#get_text() == 데이터에서 문자열만 추출\n",
    "#strip() == 데이터의 양옆 공백제거\n",
    "#[:20]의 이유? 인기검색어의 중복을 막고 20위까지만 출력하기 위함\n",
    "#keywords = [each_line.get_text().strip() for each_line in keywords[:20]]\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    info_main = input(\"=\"*50+\"\\n\"+\"입력 형식에 맞게 입력해주세요.\"+\"\\n\"+\" 시작하시려면 Enter를 눌러주세요.\"+\"\\n\"+\"=\"*50)\n",
    "    maxpage = input(\"최대 크롤링할 페이지 수 입력하시오: \")\n",
    "    query = input(\"검색어 입력: \")\n",
    "    sort = input(\"뉴스 검색 방식 입력(관련도순=0 최신순=1 오래된순=2): \") #관련도순=0 최신순=1 오래된순=2\n",
    "    s_date = input(\"시작날짜 입력(2019.02.04):\") \n",
    "    e_date = input(\"끝날짜 입력(2020.02.04):\") \n",
    "    crawler(maxpage,query,sort,s_date,e_date)\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "economic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(economic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(economic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('economic_20190204__.csv', encoding = 'UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('economic_20190204__.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame.from_records(data)\n",
    "data2.to_excel('economy.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(['정치', '경제','IT/과학' ])\n",
    "X_test = np.array(['정치', '경제', '사회'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(X_train)\n",
    "X_train_encoded = encoder.transform(X_train)\n",
    "\n",
    "# X_test데이터에만 존재하는 새로 출현한 데이터를 신규 클래스로 추가한다\n",
    "for label in np.unique(X_test):\n",
    "    if label not in encoder.classes_: # unseen label 데이터인 경우( )\n",
    "        encoder.classes_ = np.append(encoder.classes_, label) # 미처리 시 ValueError발생\n",
    "X_test_encoded = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test, '-->', X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.columns = ['economy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['economy']\n",
    "economy = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "society = pd.read_excel('society.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "society = pd.read_excel('society.xlsx', index_col =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "society.columns =['society']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "society"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([society, economy] , axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random \n",
    "import os\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\ICT01_04\\\\Documents\\\\Python2\")\n",
    "\n",
    "file = open('to_data.csv', 'r', encoding = 'utf-8')\n",
    "line = file.readlines()\n",
    "random.shuffle(line)\n",
    "rcsv = csv.reader(line)\n",
    "\n",
    "file_write = open('to_data.csv', 'w', encoding = 'utf-8', newline = \"\")\n",
    "wcsv = csv.writer(file_write)\n",
    "\n",
    "for i in rcsv:\n",
    "    try:\n",
    "        wcsv.writerow([i[0].strip(), i[1],i[2],i[3]])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "from gensim.models import Word2Vec\n",
    "import csv\n",
    "twitter = Twitter()\n",
    "\n",
    "file = open('to_data.csv', 'r', encoding = 'utf-8')\n",
    "line = csv.reader(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "to_data = pd.read_excel('to_data.xlsx',index_col =0)\n",
    "to_data.columns = ['news', 'labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15176</td>\n",
       "      <td>다뉴브강서 여성 추정 시신 1구 추가 발견…\"신원확인 중\"</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38895</td>\n",
       "      <td>[단독] 조국 딸, 대치동 학종학원서 돈 벌었다</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19367</td>\n",
       "      <td>\"시위로 체포된 10대 소녀, 홍콩 경찰에 윤간, 임신 후 낙태\"...현…</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45140</td>\n",
       "      <td>“대출도 못갚았는데 종부세라니…” vs “집값 오른 만큼 세금 내야” …</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44198</td>\n",
       "      <td>\"해외서 리콜된 제품 국내서 버젓이 유통…1위 제조국은 중국\"</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3982</td>\n",
       "      <td>뜨거웠던 붉은 밤···U-20 월드컵 결승 합계 시청률 무려 42%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23534</td>\n",
       "      <td>스페인 “북 대사관 10명이 습격”…PC 등 자료 미 FBI 건네</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22922</td>\n",
       "      <td>文, 오늘 개각…박영선 중기부-진영 행안부 가닥</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18014</td>\n",
       "      <td>[Pick] \"아빠는 누구?\"…암컷뿐인 수족관서 태어난 새끼 상어</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48170</td>\n",
       "      <td>수소차 개소세 감면 연장…넥쏘 사면 361만원 혜택</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54900 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            news  labels\n",
       "15176           다뉴브강서 여성 추정 시신 1구 추가 발견…\"신원확인 중\"       2\n",
       "38895                 [단독] 조국 딸, 대치동 학종학원서 돈 벌었다       4\n",
       "19367  \"시위로 체포된 10대 소녀, 홍콩 경찰에 윤간, 임신 후 낙태\"...현…       2\n",
       "45140   “대출도 못갚았는데 종부세라니…” vs “집값 오른 만큼 세금 내야” …       5\n",
       "44198         \"해외서 리콜된 제품 국내서 버젓이 유통…1위 제조국은 중국\"       5\n",
       "...                                          ...     ...\n",
       "3982       뜨거웠던 붉은 밤···U-20 월드컵 결승 합계 시청률 무려 42%       1\n",
       "23534       스페인 “북 대사관 10명이 습격”…PC 등 자료 미 FBI 건네       3\n",
       "22922                 文, 오늘 개각…박영선 중기부-진영 행안부 가닥       3\n",
       "18014       [Pick] \"아빠는 누구?\"…암컷뿐인 수족관서 태어난 새끼 상어       2\n",
       "48170               수소차 개소세 감면 연장…넥쏘 사면 361만원 혜택       5\n",
       "\n",
       "[54900 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import csv\n",
    "to_data.sample(frac = 1)  ## 셔플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
